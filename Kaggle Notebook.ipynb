{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk, re, string, time, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from textClassification import textAnalysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import metrics \n",
    "from sklearn import cross_validation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import operator\n",
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# automate creation of csv for kaggle submission\n",
    "def create_submission(filename, prediction):\n",
    "    pd.DataFrame.to_csv(pd.DataFrame(df_test['Id']).join(pd.DataFrame(prediction)), path_or_buf=filename, header=['Id','Category'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yell outloud 'process complete'\n",
    "def finished():\n",
    "    os.system(\"say 'process complete'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# automate crossvalidation and printing of results\n",
    "def crossvalidation(model, train_features, real_category):\n",
    "    scores = cross_validation.cross_val_score(model, train_features, real_category, cv=5)\n",
    "    print(\"Accuracy: %0.5f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"newtrain.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"newtest.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allText = \"\"\n",
    "for i in df.Text:\n",
    "    allText += i + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('allText.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.write(allText)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing functions from Text Analysis assignement on Yahoo questions text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"allText.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'textAnalysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-12a41c3d6ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'textAnalysis' is not defined"
     ]
    }
   ],
   "source": [
    "analysis = textAnalysis(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NP parsing.\n",
      "Done with NP parsing.\n",
      "Done with FD of NPs\n",
      "Extracting nouns...\n",
      "Done extracting nouns\n",
      "Done running Lesk on nouns\n",
      "Done creating FD on lemmas\n",
      "\n",
      "Most frequent noun phrases:\n",
      "---------------------------\n",
      ".how do                 91   \n",
      "br & gt                 27   \n",
      ".what do                22   \n",
      "my boyfriend            19   \n",
      "a guy                   19   \n",
      "my comput               16   \n",
      "the world               15   \n",
      "a girl                  14   \n",
      ".whi do                 11   \n",
      ".i am                   9    \n",
      ".i want                 9    \n",
      "my husband              9    \n",
      "\n",
      "\n",
      "Most frequent lemmas from NPs and their hyponyms:\n",
      "-------------------------------------------------\n",
      "can             194      (containerful.n.01)\n",
      "get             184      (return.n.11)\n",
      "know            156      (knowing.n.01)\n",
      "find            89       (act.n.02)\n",
      "need            77       (psychological_feature.n.01)\n",
      "want            70       (need.n.01)\n",
      "people          58       (group.n.01)\n",
      "someone         51       (organism.n.01)\n",
      "someone         51       (causal_agent.n.01)\n",
      "help            50       (activity.n.01)\n",
      "use             43       (custom.n.01)\n",
      "way             42       (category.n.02)\n",
      "\n",
      "\n",
      "Most frequent hyponyms:\n",
      "-----------------------\n",
      "person.n.01                    8    \n",
      "activity.n.01                  7    \n",
      "time_period.n.01               7    \n",
      "collection.n.01                4    \n",
      "computer.n.01                  3    \n",
      "woman.n.01                     3    \n",
      "content.n.05                   3    \n",
      "atmosphere.n.01                3    \n",
      "language_unit.n.01             3    \n",
      "location.n.01                  3    \n",
      "legal_document.n.01            3    \n",
      "physical_phenomenon.n.01       3    \n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences and words an run them through a POS tagger\n",
    "sentences,tagged_sents = analysis.gen_corpus_prep()\n",
    "\n",
    "# generate noun phrases and proper nouns\n",
    "nps,nps_strings,fd_nps = analysis.chunker(sentences,tagged_sents)\n",
    "\n",
    "# deduce synsets through lesk algorithm and calculate distance between synsets\n",
    "final_list,hyponyms = analysis.lesk_comparison(nps,sentences)\n",
    "\n",
    "# print final report\n",
    "analysis.final_report(fd_nps,final_list,hyponyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_dict = {1:\"Business&Finance\",2:\"Computers&Internet\",3:\"Entertainment&Music\",4:\"Family&Relationships\",5:\"Education&Reference\",6:\"Health\",7:\"Science&Mathematics\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating feature for lengths of text and converting to pandas series\n",
    "lengths = []\n",
    "for i in df.Text.iteritems():\n",
    "    lengths.append(len(i[1]))\n",
    "lengths = pd.Series(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# appending lengths feature to dataframe\n",
    "df['lengths'] = lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aggregate all text\n",
    "all_text = []\n",
    "for i in df.Text:\n",
    "    all_text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aggregate all text and tokenize it\n",
    "tok_sent = []\n",
    "for i in df.Text:\n",
    "    tok_sent.append(nltk.word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pos_tag every word\n",
    "pos_sent = []\n",
    "for i in tok_sent:\n",
    "    pos_sent.append(nltk.pos_tag(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation and Testing of Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Strategy: Count occurrence of every tag (17.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating list with all tags from upenn_tagset\n",
    "tagset = ['$', \"''\", '(', ')', ',', '--', '.', ':','CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating columns of zeroes for every possible tag\n",
    "for i in tagset:\n",
    "    df[i] = pd.Series(np.zeros(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenizing and tagging every question training set\n",
    "tagged_questions = []\n",
    "for i in df.Text:\n",
    "    tagged_questions.append(nltk.pos_tag(nltk.word_tokenize(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenizing and tagging every question for test set\n",
    "tagged_questions_test = []\n",
    "for i in df_test.Text:\n",
    "    tagged_questions_test.append(nltk.pos_tag(nltk.word_tokenize(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolassoldi/anaconda/lib/python3.4/site-packages/IPython/kernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# This is taking WAAAY too long, expected runtime > 1 hour --use sparce vector array instead\n",
    "time_check = time.time()\n",
    "for n,q in enumerate(tagged_questions[:10]): # for every tagged questios from 'df.Text'...\n",
    "    for tag in tagset: # take the list of possible tags...\n",
    "        for w in q: # for every tagged word in the question text\n",
    "            if w[1] == tag: # check if the tag matches the one the word is tagged as\n",
    "                df[tag][n] += 1 # if so, increase counter and update the dataframe\n",
    "    if n+1 % 10 == 0:\n",
    "        print(\"Done with first\",n)\n",
    "print(round((time.time() - time_check)/60, 2),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# round up all tags in one list for train data\n",
    "tags_only_train = []\n",
    "for q in tagged_questions:\n",
    "    temp = \"\"\n",
    "    for w in q:\n",
    "        temp += w[1]\n",
    "        temp += \" \"\n",
    "    tags_only_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# round up all tags in one list for test data\n",
    "tags_only_test = []\n",
    "for q in tagged_questions_test:\n",
    "    temp = \"\"\n",
    "    for w in q:\n",
    "        temp += w[1]\n",
    "        temp += \" \"\n",
    "    tags_only_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initializing vectorizer\n",
    "vec = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=5, max_features=433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags_only_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-62fc190cb060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train sparce vector array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr_train_feature_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_only_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0marr_train_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_train_feature_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0marr_train_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tags_only_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Train sparce vector array\n",
    "arr_train_feature_sparse = vec.fit_transform(pd.Series(tags_only_train))\n",
    "arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "arr_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags_only_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2b4ddf987ed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test sparce vector array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr_test_feature_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags_only_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0marr_test_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_test_feature_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0marr_test_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tags_only_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Test sparce vector array\n",
    "arr_test_feature_sparse = vec.fit_transform(pd.Series(tags_only_test))\n",
    "arr_test_feature = arr_test_feature_sparse.toarray()\n",
    "arr_test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training logistic regression with features in sparce array (arr_train_feature) and labels (df.Category)\n",
    "logreg = LogisticRegression()\n",
    "logreg_model_train = logreg.fit(arr_train_feature, df.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicting against train features in sparce array\n",
    "logreg_predictions_train = logreg_model_train.predict(arr_train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30913 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "# crossvalidating\n",
    "crossvalidation(logreg, arr_train_feature, df.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# automatically creates submission with whatever file name you pass as the argument\n",
    "create_submission(\"submission_3.csv\", 'some prediction set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 'Predict Function' to test subsequent strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to facilitate testing of variations in CountVecotrizer parameters (min_df, max_features, etc.)\n",
    "def Predict(model, vec, train_set, other_set, scoring, num_neighbors=1):\n",
    "    '''\n",
    "    model -  LogisticRegression, MultinomialNB, KNeighborsClassifier, svm\n",
    "    '''\n",
    "    # Train-data sparce vectorizing\n",
    "    arr_train_feature_sparse = vec.fit_transform(train_set.Text)\n",
    "    arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "    print(\"arr_train_feature.shape:\", arr_train_feature.shape)\n",
    "\n",
    "    # Other data sparce vectorizing\n",
    "    arr_other_feature_sparse = vec.transform(other_set.Text)\n",
    "    arr_other_feature = arr_other_feature_sparse.toarray()\n",
    "    print(\"arr_other_feature.shape:\", arr_other_feature.shape,'\\n')\n",
    "\n",
    "    # Training model with features in sparce array (arr_train_feature) and labels (df.Category)\n",
    "    if model == KNeighborsClassifier:\n",
    "        nb = model(n_neighbors = num_neighbors)\n",
    "    else:\n",
    "        nb = model\n",
    "        \n",
    "    nb_model_train = nb.fit(arr_train_feature, train_set.Category)    \n",
    "\n",
    "    # predicting against dev features in sparce array\n",
    "    nb_predictions_other = nb_model_train.predict(arr_other_feature)\n",
    "    \n",
    "    # print out crossvalidation or scoring results\n",
    "    if scoring == 'cv':\n",
    "        crossvalidation(nb, arr_train_feature, train_set.Category)\n",
    "    elif scoring == 'score': \n",
    "        print(accuracy_score(other_set.Category, nb_predictions_other))\n",
    "        \n",
    "    return nb_predictions_other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second strategy: simple vectorizer and logistic regression (20.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_train_feature.shape: (2698, 1000)\n",
      "arr_other_feature.shape: (2698, 1000) \n",
      "\n",
      "Accuracy: 0.47177 (+/- 0.06)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_predictions_test = Predict(logreg, vec, df, df, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# automatically creates submission with whatever file name you pass as the argument\n",
    "create_submission(\"submission_5.csv\", logreg_predictions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third strategy: bigram, trigram and tetragram vectorizer and logistic regression (22.6%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# notice the ngram_range parameter has \"2, 4\", so ngrams range 2 to 4\n",
    "vec = CountVectorizer(ngram_range=(2, 4), token_pattern=r'\\b\\w+\\b', min_df=5, max_features=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_train_feature.shape: (2698, 640)\n",
      "arr_other_feature.shape: (2698, 640) \n",
      "\n",
      "Accuracy: 0.34875 (+/- 0.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict(model, vec, train_set, other_set, scoring, num_neighbors = 1, gamma=False)\n",
    "logreg_predictions_test = Predict(logreg, vec, df, df, 'cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth strategy: same vectorizer but with Naive Bayes (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_train_feature.shape: (2698, 640)\n",
      "arr_other_feature.shape: (2698, 640) \n",
      "\n",
      "Accuracy: 0.34686 (+/- 0.05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# notice the ngram_range parameter has \"2, 4\", so ngrams range 2 to 4\n",
    "vec = CountVectorizer(ngram_range=(2, 4), token_pattern=r'\\b\\w+\\b', min_df=5, max_features=640)\n",
    "logreg_predictions_test = Predict(nb, vec, df, df, 'cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth strategy: Tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(min_df=1, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_train_feature.shape: (2698, 1000)\n",
      "arr_other_feature.shape: (2698, 1000) \n",
      "\n",
      "Accuracy: 0.45546 (+/- 0.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfid_test_predictions = Predict(nb, tfidf_vec, df, df, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission('submission_6.csv', tfid_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proper Nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**develop training, dev, testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>when will the new episodes of justice league u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>i dreamed that i am undressed in public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a simple riddle? what goes through a door but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the genesis of the name 401k?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>what is worse than biting an apple &amp;amp; seein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                               Text\n",
       "0         3  when will the new episodes of justice league u...\n",
       "1         3           i dreamed that i am undressed in public \n",
       "2         3  a simple riddle? what goes through a door but ...\n",
       "3         1              what is the genesis of the name 401k?\n",
       "4         3  what is worse than biting an apple &amp; seein..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_index = np.random.permutation(df.index)\n",
    "df_shuffled = df.ix[random_index]\n",
    "df_shuffled.reset_index(drop=True, inplace=True)\n",
    "df_shuffled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2698\n",
      "Columns: 2\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df_shuffled.shape\n",
    "print(\"Rows:\", rows)\n",
    "print(\"Columns:\", columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**80/20 split for training/ dev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = round(rows*.8)\n",
    "dev_size   = round(rows*.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2159, 2)\n",
      "dev: (540, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_shuffled.loc[:train_size]\n",
    "print('train:',df_train.shape)\n",
    "\n",
    "df_dev = df_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)\n",
    "print('dev:',df_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Implement voting system between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vote_winner(pair):\n",
    "    dic = {}\n",
    "    for i in range(len(pair)):\n",
    "        num = pair[i]\n",
    "        if num in dic:\n",
    "            dic[num] += 1\n",
    "        else:\n",
    "            dic[num] = 1\n",
    "    return sorted(dic.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## counting # of \"I\"\n",
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tok_sent_train = []\n",
    "for i in df_train.Text:\n",
    "    tok_sent_train.append(nltk.word_tokenize(i))\n",
    "    \n",
    "num_i_train = []\n",
    "for i in tok_sent_train:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j == \"i\":\n",
    "            count += 1\n",
    "    num_i_train.append(count)\n",
    "    \n",
    "# num_i = pd.Series(num_i)\n",
    "# df_train['num_i'] = num_i\n",
    "\n",
    "df_train_features = pd.DataFrame(num_i_train, columns=['num_i'])\n",
    "\n",
    "vec_count = tfidf_vec = TfidfVectorizer(min_df=1, max_features=1000)\n",
    "arr_train_feature_sparse = vec_count.fit_transform(df_train.Text)\n",
    "arr_train_features = arr_train_feature_sparse.toarray()\n",
    "df_train_features = df_train_features.join(pd.DataFrame(arr_train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok_sent_dev = []\n",
    "for i in df_dev.Text:\n",
    "    tok_sent_dev.append(nltk.word_tokenize(i))\n",
    "    \n",
    "num_i_dev = []\n",
    "for i in tok_sent_dev:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j == \"i\":\n",
    "            count += 1\n",
    "    num_i_dev.append(count)\n",
    "    \n",
    "# num_i_dev = pd.Series(num_i)\n",
    "# df_dev['num_i'] = num_i\n",
    "\n",
    "\n",
    "df_dev_features = pd.DataFrame(num_i_dev, columns=['num_i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_i\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr_dev_features = tfidf_vec.transform(df_dev.Text)\n",
    "df_dev_features = df_dev_features.join(pd.DataFrame(arr_dev_features.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 1001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 1, 1, 1, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb_model = nb.fit(df_train_features, df_train.Category)\n",
    "nb_predictions = nb_model.predict(df_dev_features)\n",
    "nb_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45925925925925926"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df_dev.Category, nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43443 (+/- 0.03)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossvalidation(nb_model, df_train_features, df_train.Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(min_df=1, max_features=1190, stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**test on dev set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.9, class_prior=None, fit_prior=False)\n",
    "svm_model = svm.SVC(C=800, class_weight=None, gamma=0.0, kernel='rbf')\n",
    "#train_predictions_svm = Predict(svm_model, tfidf_vec, df_train, df_train, 'cv')\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier(num_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_train_feature.shape: (2159, 1190)\n",
      "arr_other_feature.shape: (540, 1190) \n",
      "\n",
      "0.542592592593\n",
      "arr_train_feature.shape: (2159, 1190)\n",
      "arr_other_feature.shape: (540, 1190) \n",
      "\n",
      "0.535185185185\n",
      "arr_train_feature.shape: (2159, 1190)\n",
      "arr_other_feature.shape: (540, 1190) \n",
      "\n",
      "0.331481481481\n",
      "arr_train_feature.shape: (2159, 1190)\n",
      "arr_other_feature.shape: (540, 1190) \n",
      "\n",
      "Accuracy: 0.49744 (+/- 0.02)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_predictions_nb = Predict(nb, tfidf_vec, df_train, df_dev, 'score')\n",
    "dev_predictions_logreg = Predict(logreg, tfidf_vec, df_train, df_dev, 'score')\n",
    "dev_predictions_KNN = Predict(KNeighborsClassifier, tfidf_vec, df_train, df_dev, 'score')\n",
    "dev_predictions_svm = Predict(svm_model, tfidf_vec, df_train, df_dev, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voted_results_dev = [vote_winner(pair) for pair in zip(dev_predictions_logreg, dev_predictions_nb, dev_predictions_svm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_train_feature.shape: (2698, 1190)\n",
      "arr_other_feature.shape: (2698, 1190) \n",
      "\n",
      "Accuracy: 0.53256 (+/- 0.03)\n",
      "\n",
      "arr_train_feature.shape: (2698, 1190)\n",
      "arr_other_feature.shape: (2698, 1190) \n",
      "\n",
      "Accuracy: 0.50068 (+/- 0.04)\n",
      "\n",
      "arr_train_feature.shape: (2698, 1190)\n",
      "arr_other_feature.shape: (2698, 1190) \n",
      "\n",
      "Accuracy: 0.31615 (+/- 0.05)\n",
      "\n",
      "arr_train_feature.shape: (2698, 1190)\n",
      "arr_other_feature.shape: (2698, 1190) \n",
      "\n",
      "Accuracy: 0.52325 (+/- 0.06)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions_nb = Predict(nb, tfidf_vec, df, df, 'cv')\n",
    "train_predictions_logreg = Predict(logreg, tfidf_vec, df, df, 'cv')\n",
    "train_predictions_KNN = Predict(KNeighborsClassifier, tfidf_vec, df, df, 'cv')\n",
    "train_predictions_svm = Predict(svm_model, tfidf_vec, df, df, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2698,) (540,) (540,) (540,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.Category.shape,dev_predictions_logreg.shape,dev_predictions_nb.shape,dev_predictions_svm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [   3 2698]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0bf236603ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mensamble_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_predictions_logreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_predictions_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_predictions_svm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nicolassoldi/anaconda/lib/python3.4/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                              % self.C)\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicolassoldi/anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nicolassoldi/anaconda/lib/python3.4/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[0;32m--> 174\u001b[0;31m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [   3 2698]"
     ]
    }
   ],
   "source": [
    "ensamble_log = logreg.fit(pd.DataFrame([dev_predictions_logreg, dev_predictions_nb, dev_predictions_svm]), df.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crossvalidation(model, train_features, real_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit test set to Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions_nb = Predict(nb, tfidf_vec, df, df_test, 'cv')\n",
    "train_predictions_nb = Predict(nb, tfidf_vec, df, df, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(\"submission_7.csv\", test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions_logreg = Predict(LogisticRegression, tfidf_vec, df, df_test, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this one needs tuning...\n",
    "test_predictions_KNN = Predict(KNeighborsClassifier, tfidf_vec, df, df_test, 'cv', num_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tried gamma = 0.001, 0.003, 0.005 and 0.007. 0.005 has the best result\n",
    "test_predictions_svm = Predict(svm, tfidf_vec, df, df_test, 'cv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(\"submission_8.csv\", test_predictions_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply voting system between three models: logreg, nb, and svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voted_results = []\n",
    "for triple in zip(test_predictions_logreg, test_predictions_nb, test_predictions_svm):\n",
    "    voted_results.append(vote_winner(triple))\n",
    "voted_results = pd.Series(voted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.Category.shape, voted_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_submission(\"submission_9.csv\", test_predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions_nb = Predict(nb, tfidf_vec, df, df_test, 'cv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_predictions_svm = Predict(svm_model, tfidf_vec, df_train, df_train, 'cv')\n",
    "train_predictions_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Credit to Marti H. And John S. for the following function:\n",
    "def plot_confusion_matrix(cm, title, target_names, cmap=plt.cm.coolwarm):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = np.sort(df_train.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_cm = confusion_matrix(df_train.Category, train_predictions_svm)\n",
    "plot_confusion_matrix(nb_cm, \"SVM Confusion Matrix\", class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df_train.Category, train_predictions_svm, \n",
    "            rownames=['True'], colnames=['Predicted'], \n",
    "            margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cat1 = df.ix[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_temp = df_cat1['Category'] \n",
    "len(series_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_temp = df_cat1['Category'] \n",
    "for n,i in enumerate(list(series_temp)):\n",
    "    if i != 1: \n",
    "        series_temp[n] = 0\n",
    "series_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(series_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
